{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import splitext\n",
    "import PIL.Image as Image\n",
    "\n",
    "pnglist = glob( \"/home/patrick/HW3/cartoonset10k/cartoonset10k/*.[pP][nN][gG]\" )\n",
    "\n",
    "i=0\n",
    "for png in pnglist:\n",
    "    im = Image.open(png)\n",
    "    i=i+1\n",
    "    im.save('/home/patrick/HW3/cartoonset10k/cartoon/%05d'%(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "import time\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "image_size = 64*64*3\n",
    "h_dim = 400\n",
    "z_dim = 20\n",
    "num_epochs = 15\n",
    "batch_size = 100\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Create a directory if not exists\n",
    "sample_dir = 'samples'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((64, 64)), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('/home/patrick/HW3/cartoonset10k', transform) \n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)\n",
    "\n",
    "#print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/god/python3-virtual/lib/python3.5/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/home/god/python3-virtual/lib/python3.5/site-packages/ipykernel_launcher.py:51: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15], Step [10/100], Reconst Loss: 117206.2031, KL Div: 12764.6045\n",
      "Epoch[1/15], Step [20/100], Reconst Loss: 100950.1875, KL Div: 6755.6099\n",
      "Epoch[1/15], Step [30/100], Reconst Loss: 80727.9844, KL Div: 6413.7520\n",
      "Epoch[1/15], Step [40/100], Reconst Loss: 73722.4141, KL Div: 4646.9712\n",
      "Epoch[1/15], Step [50/100], Reconst Loss: 71205.9844, KL Div: 5098.8652\n",
      "Epoch[1/15], Step [60/100], Reconst Loss: 62149.2617, KL Div: 5194.8296\n",
      "Epoch[1/15], Step [70/100], Reconst Loss: 58546.2266, KL Div: 4566.7627\n",
      "Epoch[1/15], Step [80/100], Reconst Loss: 59824.1719, KL Div: 4854.9482\n",
      "Epoch[1/15], Step [90/100], Reconst Loss: 64929.7148, KL Div: 4915.0020\n",
      "Epoch[1/15], Step [100/100], Reconst Loss: 64174.3633, KL Div: 5398.9111\n",
      "Epoch[2/15], Step [10/100], Reconst Loss: 49370.8320, KL Div: 4653.7041\n",
      "Epoch[2/15], Step [20/100], Reconst Loss: 46043.3867, KL Div: 4943.3232\n",
      "Epoch[2/15], Step [30/100], Reconst Loss: 49877.7383, KL Div: 5015.3340\n",
      "Epoch[2/15], Step [40/100], Reconst Loss: 57671.3555, KL Div: 5375.4619\n",
      "Epoch[2/15], Step [50/100], Reconst Loss: 56444.3203, KL Div: 5125.5361\n",
      "Epoch[2/15], Step [60/100], Reconst Loss: 51713.1094, KL Div: 4750.9023\n",
      "Epoch[2/15], Step [70/100], Reconst Loss: 48473.6289, KL Div: 4988.7720\n",
      "Epoch[2/15], Step [80/100], Reconst Loss: 47920.5742, KL Div: 4928.8086\n",
      "Epoch[2/15], Step [90/100], Reconst Loss: 43286.2266, KL Div: 4594.5469\n",
      "Epoch[2/15], Step [100/100], Reconst Loss: 51469.8633, KL Div: 5079.1494\n",
      "Epoch[3/15], Step [10/100], Reconst Loss: 45333.7773, KL Div: 4690.9268\n",
      "Epoch[3/15], Step [20/100], Reconst Loss: 44876.8008, KL Div: 4629.6426\n",
      "Epoch[3/15], Step [30/100], Reconst Loss: 48617.7578, KL Div: 4634.8335\n",
      "Epoch[3/15], Step [40/100], Reconst Loss: 51945.8828, KL Div: 4800.9883\n",
      "Epoch[3/15], Step [50/100], Reconst Loss: 45188.9648, KL Div: 4474.3032\n",
      "Epoch[3/15], Step [60/100], Reconst Loss: 40776.6328, KL Div: 4404.1807\n",
      "Epoch[3/15], Step [70/100], Reconst Loss: 38259.4023, KL Div: 4360.8237\n",
      "Epoch[3/15], Step [80/100], Reconst Loss: 46055.4414, KL Div: 4709.9282\n",
      "Epoch[3/15], Step [90/100], Reconst Loss: 44125.3125, KL Div: 4689.2407\n",
      "Epoch[3/15], Step [100/100], Reconst Loss: 41294.5039, KL Div: 4284.7354\n",
      "Epoch[4/15], Step [10/100], Reconst Loss: 38732.0859, KL Div: 4362.9272\n",
      "Epoch[4/15], Step [20/100], Reconst Loss: 43361.8945, KL Div: 4366.9683\n",
      "Epoch[4/15], Step [30/100], Reconst Loss: 49413.8477, KL Div: 4517.1685\n",
      "Epoch[4/15], Step [40/100], Reconst Loss: 44115.3477, KL Div: 4453.6260\n",
      "Epoch[4/15], Step [50/100], Reconst Loss: 35481.7812, KL Div: 4099.4160\n",
      "Epoch[4/15], Step [60/100], Reconst Loss: 38127.5938, KL Div: 4083.6653\n",
      "Epoch[4/15], Step [70/100], Reconst Loss: 42953.7695, KL Div: 4263.5894\n",
      "Epoch[4/15], Step [80/100], Reconst Loss: 40333.4453, KL Div: 4228.2339\n",
      "Epoch[4/15], Step [90/100], Reconst Loss: 39490.8789, KL Div: 4123.2817\n",
      "Epoch[4/15], Step [100/100], Reconst Loss: 37904.6367, KL Div: 3969.8762\n",
      "Epoch[5/15], Step [10/100], Reconst Loss: 41201.1406, KL Div: 4120.5835\n",
      "Epoch[5/15], Step [20/100], Reconst Loss: 40463.1836, KL Div: 4153.5732\n",
      "Epoch[5/15], Step [30/100], Reconst Loss: 39349.8008, KL Div: 4127.2534\n",
      "Epoch[5/15], Step [40/100], Reconst Loss: 38124.1016, KL Div: 3932.5073\n",
      "Epoch[5/15], Step [50/100], Reconst Loss: 45408.4375, KL Div: 4383.9058\n",
      "Epoch[5/15], Step [60/100], Reconst Loss: 37953.8008, KL Div: 4218.8350\n",
      "Epoch[5/15], Step [70/100], Reconst Loss: 41126.5508, KL Div: 4168.0708\n",
      "Epoch[5/15], Step [80/100], Reconst Loss: 39677.2227, KL Div: 3859.6272\n",
      "Epoch[5/15], Step [90/100], Reconst Loss: 36713.0586, KL Div: 3872.4326\n",
      "Epoch[5/15], Step [100/100], Reconst Loss: 37097.0625, KL Div: 3881.4065\n",
      "Epoch[6/15], Step [10/100], Reconst Loss: 39860.1172, KL Div: 4164.5933\n",
      "Epoch[6/15], Step [20/100], Reconst Loss: 41163.8906, KL Div: 4049.3391\n",
      "Epoch[6/15], Step [30/100], Reconst Loss: 36005.3164, KL Div: 3910.3303\n",
      "Epoch[6/15], Step [40/100], Reconst Loss: 42512.5625, KL Div: 3963.5010\n",
      "Epoch[6/15], Step [50/100], Reconst Loss: 41190.3711, KL Div: 3907.5605\n",
      "Epoch[6/15], Step [60/100], Reconst Loss: 40939.7422, KL Div: 4233.9941\n",
      "Epoch[6/15], Step [70/100], Reconst Loss: 37396.6484, KL Div: 3892.2817\n",
      "Epoch[6/15], Step [80/100], Reconst Loss: 37655.4727, KL Div: 3841.7136\n",
      "Epoch[6/15], Step [90/100], Reconst Loss: 39622.0312, KL Div: 3894.2925\n",
      "Epoch[6/15], Step [100/100], Reconst Loss: 40657.6445, KL Div: 4036.9543\n",
      "Epoch[7/15], Step [10/100], Reconst Loss: 43998.7227, KL Div: 4152.4326\n",
      "Epoch[7/15], Step [20/100], Reconst Loss: 36638.2969, KL Div: 3892.9883\n",
      "Epoch[7/15], Step [30/100], Reconst Loss: 40611.8203, KL Div: 3865.8652\n",
      "Epoch[7/15], Step [40/100], Reconst Loss: 40836.1328, KL Div: 3894.2942\n",
      "Epoch[7/15], Step [50/100], Reconst Loss: 39334.0000, KL Div: 3799.5742\n",
      "Epoch[7/15], Step [60/100], Reconst Loss: 37803.8984, KL Div: 3848.1418\n",
      "Epoch[7/15], Step [70/100], Reconst Loss: 38496.3828, KL Div: 3894.8713\n",
      "Epoch[7/15], Step [80/100], Reconst Loss: 33057.8555, KL Div: 3729.5715\n",
      "Epoch[7/15], Step [90/100], Reconst Loss: 33305.1641, KL Div: 3611.1250\n",
      "Epoch[7/15], Step [100/100], Reconst Loss: 36576.9766, KL Div: 3638.7153\n",
      "Epoch[8/15], Step [10/100], Reconst Loss: 37508.7422, KL Div: 3752.1025\n",
      "Epoch[8/15], Step [20/100], Reconst Loss: 35955.0859, KL Div: 3845.0225\n",
      "Epoch[8/15], Step [30/100], Reconst Loss: 38637.2969, KL Div: 3845.0654\n",
      "Epoch[8/15], Step [40/100], Reconst Loss: 40972.7617, KL Div: 3974.3164\n",
      "Epoch[8/15], Step [50/100], Reconst Loss: 35066.4336, KL Div: 3684.6401\n",
      "Epoch[8/15], Step [60/100], Reconst Loss: 33602.7617, KL Div: 3817.8716\n",
      "Epoch[8/15], Step [70/100], Reconst Loss: 43333.7891, KL Div: 4013.8345\n",
      "Epoch[8/15], Step [80/100], Reconst Loss: 37256.0508, KL Div: 3715.6807\n",
      "Epoch[8/15], Step [90/100], Reconst Loss: 38493.5469, KL Div: 3727.1343\n",
      "Epoch[8/15], Step [100/100], Reconst Loss: 40041.7266, KL Div: 4028.8633\n",
      "Epoch[9/15], Step [10/100], Reconst Loss: 30321.1953, KL Div: 3516.0906\n",
      "Epoch[9/15], Step [20/100], Reconst Loss: 39796.4609, KL Div: 3857.2085\n",
      "Epoch[9/15], Step [30/100], Reconst Loss: 42642.1289, KL Div: 3796.7415\n",
      "Epoch[9/15], Step [40/100], Reconst Loss: 43386.8633, KL Div: 4088.9458\n",
      "Epoch[9/15], Step [50/100], Reconst Loss: 32522.7500, KL Div: 3615.1326\n",
      "Epoch[9/15], Step [60/100], Reconst Loss: 36533.4766, KL Div: 3799.1289\n",
      "Epoch[9/15], Step [70/100], Reconst Loss: 40400.9766, KL Div: 3703.0793\n",
      "Epoch[9/15], Step [80/100], Reconst Loss: 40758.4219, KL Div: 3828.9231\n",
      "Epoch[9/15], Step [90/100], Reconst Loss: 33561.8203, KL Div: 3562.1208\n",
      "Epoch[9/15], Step [100/100], Reconst Loss: 33871.8203, KL Div: 3720.5408\n",
      "Epoch[10/15], Step [10/100], Reconst Loss: 38932.0742, KL Div: 3825.2588\n",
      "Epoch[10/15], Step [20/100], Reconst Loss: 40450.6094, KL Div: 3640.4509\n",
      "Epoch[10/15], Step [30/100], Reconst Loss: 36809.7852, KL Div: 3751.9478\n",
      "Epoch[10/15], Step [40/100], Reconst Loss: 39785.5469, KL Div: 3882.5371\n",
      "Epoch[10/15], Step [50/100], Reconst Loss: 39038.4766, KL Div: 3718.9351\n",
      "Epoch[10/15], Step [60/100], Reconst Loss: 38121.5156, KL Div: 3716.5935\n",
      "Epoch[10/15], Step [70/100], Reconst Loss: 32138.1230, KL Div: 3507.2793\n",
      "Epoch[10/15], Step [80/100], Reconst Loss: 39424.9375, KL Div: 3892.4836\n",
      "Epoch[10/15], Step [90/100], Reconst Loss: 36198.6953, KL Div: 3728.8384\n",
      "Epoch[10/15], Step [100/100], Reconst Loss: 34979.1523, KL Div: 3644.8723\n",
      "Epoch[11/15], Step [10/100], Reconst Loss: 34005.6133, KL Div: 3652.1907\n",
      "Epoch[11/15], Step [20/100], Reconst Loss: 40630.2891, KL Div: 3721.3257\n",
      "Epoch[11/15], Step [30/100], Reconst Loss: 33678.6172, KL Div: 3589.5789\n",
      "Epoch[11/15], Step [40/100], Reconst Loss: 38729.4648, KL Div: 3631.8020\n",
      "Epoch[11/15], Step [50/100], Reconst Loss: 33515.1406, KL Div: 3697.3188\n",
      "Epoch[11/15], Step [60/100], Reconst Loss: 46364.0664, KL Div: 4027.6272\n",
      "Epoch[11/15], Step [70/100], Reconst Loss: 30910.2285, KL Div: 3435.0610\n",
      "Epoch[11/15], Step [80/100], Reconst Loss: 37913.3906, KL Div: 3776.0283\n",
      "Epoch[11/15], Step [90/100], Reconst Loss: 43592.5273, KL Div: 3883.1143\n",
      "Epoch[11/15], Step [100/100], Reconst Loss: 32444.6719, KL Div: 3558.2654\n",
      "Epoch[12/15], Step [10/100], Reconst Loss: 39607.4766, KL Div: 3651.6121\n",
      "Epoch[12/15], Step [20/100], Reconst Loss: 35387.5664, KL Div: 3661.7395\n",
      "Epoch[12/15], Step [30/100], Reconst Loss: 40022.2227, KL Div: 3589.0664\n",
      "Epoch[12/15], Step [40/100], Reconst Loss: 40390.5078, KL Div: 3745.9714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[12/15], Step [50/100], Reconst Loss: 32141.1797, KL Div: 3746.0681\n",
      "Epoch[12/15], Step [60/100], Reconst Loss: 38562.0625, KL Div: 3746.6362\n",
      "Epoch[12/15], Step [70/100], Reconst Loss: 37936.4805, KL Div: 3706.3892\n",
      "Epoch[12/15], Step [80/100], Reconst Loss: 33717.1562, KL Div: 3386.9714\n",
      "Epoch[12/15], Step [90/100], Reconst Loss: 34492.2422, KL Div: 3700.0610\n",
      "Epoch[12/15], Step [100/100], Reconst Loss: 35933.1406, KL Div: 3702.3079\n",
      "Epoch[13/15], Step [10/100], Reconst Loss: 34117.2227, KL Div: 3475.5972\n",
      "Epoch[13/15], Step [20/100], Reconst Loss: 32748.1289, KL Div: 3481.0027\n",
      "Epoch[13/15], Step [30/100], Reconst Loss: 36853.4922, KL Div: 3721.7722\n",
      "Epoch[13/15], Step [40/100], Reconst Loss: 35877.4922, KL Div: 3787.7500\n",
      "Epoch[13/15], Step [50/100], Reconst Loss: 32790.5938, KL Div: 3614.7427\n",
      "Epoch[13/15], Step [60/100], Reconst Loss: 33353.2930, KL Div: 3596.2979\n",
      "Epoch[13/15], Step [70/100], Reconst Loss: 35612.8672, KL Div: 3758.5723\n",
      "Epoch[13/15], Step [80/100], Reconst Loss: 40797.3242, KL Div: 3706.8596\n",
      "Epoch[13/15], Step [90/100], Reconst Loss: 39432.7422, KL Div: 3556.4482\n",
      "Epoch[13/15], Step [100/100], Reconst Loss: 34960.2656, KL Div: 3543.1782\n",
      "Epoch[14/15], Step [10/100], Reconst Loss: 34090.5430, KL Div: 3592.7444\n",
      "Epoch[14/15], Step [20/100], Reconst Loss: 38838.3828, KL Div: 3631.9487\n",
      "Epoch[14/15], Step [30/100], Reconst Loss: 34574.9805, KL Div: 3448.0046\n",
      "Epoch[14/15], Step [40/100], Reconst Loss: 32668.4883, KL Div: 3464.3115\n",
      "Epoch[14/15], Step [50/100], Reconst Loss: 38819.2891, KL Div: 3599.7239\n",
      "Epoch[14/15], Step [60/100], Reconst Loss: 34975.6484, KL Div: 3637.8491\n",
      "Epoch[14/15], Step [70/100], Reconst Loss: 42199.7188, KL Div: 3888.1035\n",
      "Epoch[14/15], Step [80/100], Reconst Loss: 34718.5703, KL Div: 3592.8213\n",
      "Epoch[14/15], Step [90/100], Reconst Loss: 37139.9102, KL Div: 3640.0588\n",
      "Epoch[14/15], Step [100/100], Reconst Loss: 38082.7305, KL Div: 3528.2483\n",
      "Epoch[15/15], Step [10/100], Reconst Loss: 36689.5078, KL Div: 3606.5466\n",
      "Epoch[15/15], Step [20/100], Reconst Loss: 32819.5391, KL Div: 3592.1914\n",
      "Epoch[15/15], Step [30/100], Reconst Loss: 38630.7930, KL Div: 3496.1165\n",
      "Epoch[15/15], Step [40/100], Reconst Loss: 35801.8594, KL Div: 3428.9790\n",
      "Epoch[15/15], Step [50/100], Reconst Loss: 37780.8555, KL Div: 3498.5554\n",
      "Epoch[15/15], Step [60/100], Reconst Loss: 37599.2266, KL Div: 3672.6584\n",
      "Epoch[15/15], Step [70/100], Reconst Loss: 38378.6133, KL Div: 3691.2327\n",
      "Epoch[15/15], Step [80/100], Reconst Loss: 35032.8398, KL Div: 3468.3757\n",
      "Epoch[15/15], Step [90/100], Reconst Loss: 40429.9023, KL Div: 3591.8115\n",
      "Epoch[15/15], Step [100/100], Reconst Loss: 35226.1875, KL Div: 3486.4556\n",
      "Total cost time 00 hr 11 min 35 sec\n"
     ]
    }
   ],
   "source": [
    "# VAE model\n",
    "start_time = time.time()\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_size=64*64*3, h_dim=400, z_dim=20):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(image_size, h_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
    "        self.fc5 = nn.Linear(h_dim, image_size)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        return self.fc2(h), self.fc3(h)\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(log_var/2)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        return torch.sigmoid(self.fc5(h))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_reconst = self.decode(z)\n",
    "        return x_reconst, mu, log_var\n",
    "\n",
    "model = VAE().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "v_loss  = []\n",
    "# Start training\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (x, _) in enumerate(data_loader):\n",
    "        # Forward pass\n",
    "        x = x.to(device).view(-1, image_size)\n",
    "        x_reconst, mu, log_var = model(x)\n",
    "        \n",
    "        # Compute reconstruction loss and kl divergence\n",
    "        reconst_loss = F.mse_loss(x_reconst, x, size_average=False)\n",
    "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        loss = reconst_loss + kl_div\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        v_loss.append(loss.data[0])\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\" \n",
    "                   .format(epoch+1, num_epochs, i+1, len(data_loader), reconst_loss.item(), kl_div.item()))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Save the sampled images\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        out = model.decode(z).view(-1, 3, 64, 64)\n",
    "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
    "\n",
    "        # Save the reconstructed images\n",
    "        out, _, _ = model(x)\n",
    "        x_concat = torch.cat([x.view(-1, 3, 64, 64), out.view(-1, 3, 64, 64)], dim=3)\n",
    "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))\n",
    "        \n",
    "end_time = time.time()\n",
    "print('Total cost time',\n",
    "      time.strftime(\"%H hr %M min %S sec\", time.gmtime(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot learning curve\n",
    "plt.plot(v_loss, label=\"loss\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.savefig(\"loss\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-virtual",
   "language": "python",
   "name": "python3-virtual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
